services:
  chain:
    container_name: chain
    image: ghcr.io/foundry-rs/foundry:v1.0.0
    ports: ["127.0.0.1:${CHAIN_RPC}:8545"]
    command: ["anvil --host=0.0.0.0 --chain-id=1337 --base-fee=0"]
    healthcheck: 
      { interval: 1s, retries: 10, test: cast block }

  ipfs:
    container_name: ipfs
    image: ipfs/kubo:v0.34.1
    ports: ["127.0.0.1:${IPFS_RPC}:5001"]
    environment:
      IPFS_PROFILE: server
    healthcheck: 
      { interval: 1s, retries: 50, test: ipfs id }

  postgres:
    container_name: postgres
    image: postgres:17-alpine
    ports: ["127.0.0.1:${POSTGRES}:5432"]
    command: postgres -c 'max_connections=1000' -c 'shared_preload_libraries=pg_stat_statements'
    volumes:
      - ./postgres/setup.sql:/docker-entrypoint-initdb.d/setup.sql:ro
    environment:
      POSTGRES_INITDB_ARGS: "--encoding UTF8 --locale=C"
      POSTGRES_HOST_AUTH_METHOD: trust
      POSTGRES_USER: postgres
    healthcheck:
      { interval: 1s, retries: 20, test: pg_isready -U postgres }

  graph-node:
    container_name: graph-node
    build: { context: "graph-node" }
    depends_on:
      chain: { condition: service_healthy }
      ipfs: { condition: service_healthy }
      postgres: { condition: service_healthy }
    stop_signal: SIGKILL
    ports:
      - 127.0.0.1:${GRAPH_NODE_GRAPHQL}:8000
      - 127.0.0.1:${GRAPH_NODE_ADMIN}:8020
      - 127.0.0.1:${GRAPH_NODE_STATUS}:8030
      - 127.0.0.1:${GRAPH_NODE_METRICS}:8040
    volumes:
      - ./.env:/opt/.env:ro
    healthcheck:
      { interval: 1s, retries: 20, test: curl -f http://127.0.0.1:8030 }

  graph-contracts:
    container_name: graph-contracts
    build: { context: graph-contracts }
    depends_on:
      graph-node: { condition: service_healthy }
    volumes:
      - ./.env:/opt/.env:ro
      - ./contracts.json:/opt/contracts.json:ro

  tap-contracts:
    container_name: tap-contracts
    build: { context: tap-contracts }
    depends_on:
      graph-contracts: { condition: service_completed_successfully }
    volumes:
      - ./.env:/opt/.env:ro
      - ./contracts.json:/opt/contracts.json:ro

  block-oracle:
    container_name: block-oracle
    build: { context: block-oracle }
    depends_on:
      tap-contracts: { condition: service_completed_successfully }
    stop_signal: SIGKILL
    volumes:
      - ./.env:/opt/.env:ro
      - ./contracts.json:/opt/contracts.json:ro
    environment:
      RUST_BACKTRACE: full
    healthcheck:
      { interval: 1s, retries: 600, test: curl -f http://127.0.0.1:9090/metrics }

  indexer-agent:
    container_name: indexer-agent
    build: { 
      target: "wrapper-dev",  # Set to "wrapper-dev" for building from source
      context: indexer-agent,
    }
    depends_on:
      block-oracle: { condition: service_healthy }
    ports: ["127.0.0.1:${INDEXER_MANAGEMENT}:7600"]
    stop_signal: SIGKILL
    volumes:
      - ./.env:/opt/.env:ro
      - ./contracts.json:/opt/contracts.json:ro
    healthcheck:
      { interval: 10s, retries: 600, test: curl -f http://127.0.0.1:7600/ }

  subgraph-deploy:
    container_name: subgraph-deploy
    build: { context: subgraph-deploy }
    depends_on:
      graph-node: { condition: service_healthy }
      indexer-agent: { condition: service_healthy }
      ipfs: { condition: service_healthy }
      chain: { condition: service_healthy }
    volumes:
      - ./.env:/opt/.env:ro
      - ./contracts.json:/opt/contracts.json:ro

  indexer-service:
    container_name: indexer-service
    build: { 
      target: "wrapper-dev", # Set to "wrapper-dev" for building from source
      context: indexer-service,
    }
    depends_on:
      indexer-agent: { condition: service_healthy }
      ipfs: { condition: service_healthy }
      tap-escrow-manager: { condition: service_started }
    ports: [
      "127.0.0.1:${INDEXER_SERVICE}:7601",
      "127.0.0.1:${INDEXER_SERVICE_DIPS_RPC_PORT}:7602"
    ]
    stop_signal: SIGKILL
    volumes:
      - ./.env:/opt/.env:ro
      - ./contracts.json:/opt/contracts.json:ro
    environment:
      RUST_LOG: info,indexer_service_rs=info,indexer_monitor=debug,indexer_dips=debug
      RUST_BACKTRACE: 1
    healthcheck:
      { interval: 1s, retries: 100, test: curl -f http://127.0.0.1:7601/ }

  tap-aggregator:
    container_name: tap-aggregator
    build: { context: tap-aggregator }
    depends_on:
      tap-contracts: { condition: service_completed_successfully }
    ports: ["127.0.0.1:${TAP_AGGREGATOR}:7610"]
    stop_signal: SIGKILL
    volumes:
      - ./.env:/opt/.env:ro
      - ./contracts.json:/opt/contracts.json:ro

  tap-agent:
    container_name: tap-agent
    build: { context: tap-agent }
    depends_on:
      indexer-agent: { condition: service_healthy }
    stop_signal: SIGKILL
    volumes:
      - ./.env:/opt/.env:ro
      - ./contracts.json:/opt/contracts.json:ro

  redpanda:
    container_name: redpanda
    image: docker.redpanda.com/redpandadata/redpanda:v23.3.5
    ports:
      - 127.0.0.1:${REDPANDA_KAFKA}:9092
      - 127.0.0.1:${REDPANDA_ADMIN}:9644
      - 127.0.0.1:${REDPANDA_PANDAPROXY}:8082
      - 127.0.0.1:${REDPANDA_SCHEMA_REGISTRY}:8081
    command:
      - redpanda start
      - --smp 1
      - --memory 1G
      - --mode dev-container
      - --default-log-level=info
      - --kafka-addr 0.0.0.0:9092
      - --advertise-kafka-addr redpanda:9092
      - --pandaproxy-addr 0.0.0.0:8082
      - --schema-registry-addr 0.0.0.0:8081
    healthcheck:
      { interval: 1s, retries: 600, test: rpk topic list --brokers="localhost:9092" }

  tap-escrow-manager:
    container_name: tap-escrow-manager
    build: { context: tap-escrow-manager }
    depends_on:
      redpanda: { condition: service_healthy }
      subgraph-deploy: { condition: service_completed_successfully }
    stop_signal: SIGKILL
    volumes:
      - ./.env:/opt/.env:ro
      - ./contracts.json:/opt/contracts.json:ro

  gateway:
    container_name: gateway
    build: { context: gateway }
    depends_on:
      subgraph-deploy: { condition: service_completed_successfully }
      indexer-service: { condition: service_healthy }
      redpanda: { condition: service_healthy }
      tap-escrow-manager: { condition: service_started }
    ports: ["127.0.0.1:${GATEWAY}:7700"]
    stop_signal: SIGKILL
    volumes:
      - ./.env:/opt/.env:ro
      - ./contracts.json:/opt/contracts.json:ro
    environment:
      RUST_LOG: info,graph_gateway=trace
    restart: on-failure:3
    healthcheck:
      { interval: 1s, retries: 100, test: curl -f http://127.0.0.1:7700/ }

  dipper:
    container_name: dipper
    build: { 
      target: "wrapper-dev", # Set to "wrapper-dev" for building from source
      context: dipper
    }
    depends_on:
      gateway: { condition: service_healthy }
      postgres: { condition: service_healthy }
    ports:
      - "127.0.0.1:${DIPPER_ADMIN_RPC_PORT}:9000"
      - "127.0.0.1:${DIPPER_INDEXER_RPC_PORT}:9001"
    stop_signal: SIGKILL
    environment:
      RUST_LOG: info,dipper_service=trace,dipper_service::network=info
      RUST_BACKTRACE: 1
    volumes:
      - ./.env:/opt/.env:ro
      - ./contracts.json:/opt/contracts.json:ro
    restart: on-failure:10
    healthcheck:
      { interval: 5s, retries: 100, test: curl -f http://127.0.0.1:9000/ }
